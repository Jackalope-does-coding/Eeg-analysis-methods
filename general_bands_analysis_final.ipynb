{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f8757-b132-447b-9f0e-cc38afc3876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the psychopy csv:\n",
    "#\"Stimulus\" is the name of the csv column for event type\n",
    "#\"Marker Timestamp\" is the name of the csv column for when the event occured\n",
    "#These are present in 2 places in the code.\n",
    "#The names should be changed in the code or in the csv if different names are being used\n",
    "#The following locations are the bits of code that mention these columns:\n",
    "\n",
    "\"\"\"\n",
    "#First in the load_behav function:\n",
    "\n",
    "beh = pd.read_csv(behav_csv)\n",
    "beh = beh.dropna(subset=['Marker Timestamp', 'Stimulus'])                #This line!!\n",
    "\n",
    "beh['marker_ts'] = pd.to_datetime(\n",
    "    beh['Marker Timestamp'], utc=True                                    #This line!!\n",
    ").apply(lambda ts: ts.timestamp())\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#Second when generating the marker map\n",
    "\n",
    "unique_stimuli = beh_df['Stimulus'].unique()                             #This line!!\n",
    "marker_map = {stim: i + 1 for i, stim in enumerate(unique_stimuli)}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Change those lines further down in the actual code as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d7ed5-30f7-4df5-b218-5ee935876b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mne PyWavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a2751-37b0-42cc-8f45-47341a76c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import mne\n",
    "from scipy import signal, integrate\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilenames\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a9355-5268-4962-85ca-80994440b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure only forward slashes are used!! \n",
    "#Also, be careful to copy the file name exactly! Any extra characters, even a space at the end, and it will give you an error message!\n",
    "\n",
    "eeg_file = r\"/Users/username/Desktop/folder/eeg_data.csv\" #replace with the filepath to your eeg csv\n",
    "behav_file = r\"/Users/username/Desktop/folder/psychopy_data.csv\" #replace with the filepath to your psychopy csv\n",
    "\n",
    "# ✅ Load the files\n",
    "eeg_df = load_eeg(eeg_file)\n",
    "beh_df = load_behav(behav_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483527d5-c51e-43f7-a105-d45a613b16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh_df_raw = pd.read_csv(behav_file)\n",
    "behav_df_raw = pd.read_csv(behav_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec7939e-bad1-4c56-b750-6cc0e7eed73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg(eeg_csv: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(eeg_csv, sep=None, engine='python')\n",
    "    df['timestamps'] = df['timestamps'].astype(float)\n",
    "    return df\n",
    "\n",
    "def load_behav(behav_csv: str, ts_col: str = 'Marker Timestamp') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads the psychopy behavioral CSV, converts timestamps to Unix seconds.\n",
    "    \"\"\"\n",
    "    beh = pd.read_csv(behav_csv)\n",
    "    beh['marker_ts'] = (\n",
    "        pd.to_datetime(beh[ts_col])\n",
    "          .astype(np.int64) / 1e9\n",
    "    )\n",
    "    return beh.dropna(subset=['marker_ts'])\n",
    "\n",
    "\n",
    "beh_df = behav_df_raw.copy()\n",
    "beh_df[\"marker_ts\"] = beh_df[\"Marker Timestamp\"]  # Already in Unix seconds, so just rename\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"EEG timestamps range:\")\n",
    "print(\"Start:\", eeg_df[\"timestamps\"].min())\n",
    "print(\"End  :\", eeg_df[\"timestamps\"].max())\n",
    "\n",
    "print(\"\\nBehavioral timestamps (marker_ts) range:\")\n",
    "print(\"Start:\", beh_df[\"marker_ts\"].min())\n",
    "print(\"End  :\", beh_df[\"marker_ts\"].max())\n",
    "\n",
    "# Calculate intersection\n",
    "start_ts = max(eeg_df[\"timestamps\"].min(), beh_df[\"marker_ts\"].min())\n",
    "end_ts   = min(eeg_df[\"timestamps\"].max(), beh_df[\"marker_ts\"].max())\n",
    "print(\"\\nCommon overlap window:\")\n",
    "print(\"Start:\", start_ts)\n",
    "print(\"End  :\", end_ts)\n",
    "\n",
    "# Extract EEG slice that matches\n",
    "eeg_sync = eeg_df[(eeg_df[\"timestamps\"] >= start_ts) & (eeg_df[\"timestamps\"] <= end_ts)]\n",
    "print(f\"\\n🧪 EEG samples in overlap window: {len(eeg_sync)}\")\n",
    "\n",
    "\n",
    "def sync_and_mark(\n",
    "    eeg_df: pd.DataFrame,\n",
    "    beh_df: pd.DataFrame,\n",
    "    marker_map: dict,\n",
    "    fs: int = 256\n",
    ") -> pd.DataFrame:\n",
    "    start_ts = max(eeg_df['timestamps'].min(), beh_df['marker_ts'].min())\n",
    "    end_ts   = min(eeg_df['timestamps'].max(), beh_df['marker_ts'].max())\n",
    "    eeg_sync = eeg_df.query(\"@start_ts <= timestamps <= @end_ts\").copy()\n",
    "    eeg_sync['marker'] = 0\n",
    "    times = eeg_sync['timestamps'].values\n",
    "    for _, row in beh_df.iterrows():\n",
    "        code = marker_map.get(row['Marker'], 0)\n",
    "        idx  = np.argmin(np.abs(times - row['marker_ts']))\n",
    "        eeg_sync.at[eeg_sync.index[idx], 'marker'] = code\n",
    "    return eeg_sync.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb5637e-4d7a-4a61-b730-be0c17230125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Rename for consistency with extended pipeline\n",
    "beh_df_raw[\"marker_ts_raw\"] = beh_df_raw[\"Marker Timestamp\"]\n",
    "\n",
    "# Apply simple Unix-to-datetime conversion (no offset)\n",
    "beh_df_raw[\"marker_ts\"] = pd.to_datetime(beh_df_raw[\"marker_ts_raw\"], unit='s')\n",
    "\n",
    "beh_df = beh_df_raw.copy()\n",
    "beh_df[\"marker_ts\"] = beh_df[\"marker_ts_raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084f8fb-e2f5-4e65-b340-a497724188fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ica(raw, n_components, eog_thresh=2.5):\n",
    "    # Skip ICA if data is too short or variance is degenerate\n",
    "    data = raw.get_data()\n",
    "    if data.shape[1] < 20 or np.isnan(data).any() or np.allclose(data, 0):\n",
    "        print(\"⚠️ Skipping ICA: insufficient data duration or invalid signal\")\n",
    "        return raw\n",
    "\n",
    "    # Proceed with ICA\n",
    "    ica = mne.preprocessing.ICA(\n",
    "        n_components=n_components,\n",
    "        max_iter='auto',\n",
    "        random_state=0\n",
    "    )\n",
    "    try:\n",
    "        ica.fit(raw)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ICA failed: {e}\")\n",
    "        return raw\n",
    "\n",
    "    # Optionally exclude EOG-like components (if present)\n",
    "    try:\n",
    "        eog_indices, scores = ica.find_bads_eog(raw, threshold=eog_thresh)\n",
    "        ica.exclude = eog_indices\n",
    "        raw = ica.apply(raw.copy())\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ EOG removal skipped: {e}\")\n",
    "\n",
    "    return raw\n",
    "\n",
    "\n",
    "\n",
    "def wavelet_denoise(sig, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(sig, wavelet, level=level)\n",
    "    sigma  = np.median(np.abs(coeffs[-level])) / 0.6745\n",
    "    uthresh= sigma * np.sqrt(2*np.log(len(sig)))\n",
    "    coeffs[1:] = [pywt.threshold(c, uthresh, mode='hard') for c in coeffs[1:]]\n",
    "    return pywt.waverec(coeffs, wavelet)[:len(sig)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ef5ad-564d-42dc-8122-c4fbebb97ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recording:\n",
    "    def __init__(\n",
    "        self,\n",
    "        eeg_df: pd.DataFrame,\n",
    "        beh_df: pd.DataFrame,\n",
    "        marker_map: dict,\n",
    "        length: float = 20,\n",
    "        bands: dict = None,\n",
    "        fs: int = 256,\n",
    "        min_freq: float = 1,\n",
    "        max_freq: float = 30\n",
    "    ):\n",
    "        self.fs = fs\n",
    "        self.length = length\n",
    "        self.marker_map = marker_map\n",
    "        # reverse map: code → label\n",
    "        self.marker_dict = {v:k for k,v in marker_map.items()}\n",
    "        self.bands = bands or {\n",
    "            \"delta\": [0.5,4], \"theta\":[4,8],\n",
    "            \"alpha\":[8,12],\"beta\":[12,30]\n",
    "        }\n",
    "        self.beh = beh_df  # store behavioral data for diagnostics\n",
    "\n",
    "\n",
    "        # 1. Sync streams & inject markers\n",
    "        merged = sync_and_mark(eeg_df, beh_df, marker_map, fs)\n",
    "        picks = ['TP9','AF7','AF8','TP10']\n",
    "        \n",
    "        # 2. Create MNE Raw, filter, ICA\n",
    "        data = merged[picks].T.values * 1e-6  # µV → V\n",
    "        info = mne.create_info(picks, fs, ['eeg']*4)\n",
    "        raw  = mne.io.RawArray(data, info, verbose=False)\n",
    "        raw.filter(min_freq, max_freq, method='iir', verbose=False)\n",
    "        # use exactly as many ICA components as you have channels\n",
    "        \n",
    "        \n",
    "        n_ica_components = min(len(picks), raw.info['nchan'], raw.get_data().shape[0])\n",
    "        raw = apply_ica(raw, n_components=n_ica_components)\n",
    "\n",
    "\n",
    "        # 3. Update dataframe with cleaned data (µV)\n",
    "        clean = (raw.get_data().T * 1e6)\n",
    "        for i,ch in enumerate(picks):\n",
    "            merged[ch] = clean[:,i]\n",
    "\n",
    "        self.df = merged\n",
    "        self._epoch_fixed_length(picks)\n",
    "        self._clean_windows(threshold=200) # CHANGE THE THRESHOLD NUMBER DEPENDING ON HOW EXACT YOU WANT THE RESULTS\n",
    "        self._compute_welch()\n",
    "        self._compute_band_power()\n",
    "\n",
    "    def _epoch_fixed_length(self, picks):\n",
    "        n_pts = int(self.length * self.fs)\n",
    "        self.events = {code:{ch:[] for ch in picks} for code in self.marker_dict}\n",
    "        idxs = self.df.index[self.df['marker']!=0]\n",
    "        for idx in idxs:\n",
    "            code = int(self.df.at[idx,'marker'])\n",
    "            for ch in picks:\n",
    "                segment = self.df[ch].iloc[idx: idx+n_pts].values\n",
    "                if len(segment)==n_pts:\n",
    "                    self.events[code][ch].append(segment)\n",
    "\n",
    "    def _clean_windows(self, threshold=100):\n",
    "        self.windows = {c:{ch:[] for ch in self.events[c]} for c in self.events}\n",
    "        size = n = int(self.length*self.fs//4)\n",
    "        for c in self.events:\n",
    "            for ch, segs in self.events[c].items():\n",
    "                for seg in segs:\n",
    "                    # split into 4 sub-windows\n",
    "                    for j in range(0, len(seg), size):\n",
    "                        w = seg[j:j+size]\n",
    "                        if np.max(np.abs(w)) < threshold:\n",
    "                            self.windows[c][ch].append(w)\n",
    "\n",
    "    def _compute_welch(self):\n",
    "        self.freqs = None\n",
    "        self.psd = {c: {ch: None for ch in self.windows[c]} for c in self.windows}\n",
    "        win = int(self.length * self.fs)\n",
    "    \n",
    "        for c in self.windows:\n",
    "            for ch, ws in self.windows[c].items():\n",
    "                psds = []\n",
    "                freqs_list = []\n",
    "    \n",
    "                for w in ws:\n",
    "                    f, Pxx = signal.welch(w, fs=self.fs, nperseg=win)\n",
    "                    psds.append(Pxx)\n",
    "                    freqs_list.append(np.round(f, 3))  # Round to make comparable\n",
    "    \n",
    "                if not psds:\n",
    "                    continue  # Skip if no valid windows\n",
    "    \n",
    "                # Use the most common frequency array\n",
    "                freq_keys = [tuple(f) for f in freqs_list]\n",
    "                most_common_freq_key = pd.Series(freq_keys).value_counts().idxmax()\n",
    "                most_common_freq = np.array(most_common_freq_key)\n",
    "    \n",
    "                self.freqs = most_common_freq\n",
    "                matched_psds = [ps for ps, f in zip(psds, freqs_list) if np.allclose(f, most_common_freq)]\n",
    "    \n",
    "                self.psd[c][ch] = np.mean(matched_psds, axis=0) if matched_psds else None\n",
    "    \n",
    "                    \n",
    "\n",
    "    def _compute_band_power(self):\n",
    "\n",
    "        if self.freqs is None:\n",
    "            print(\"⚠️ No frequency data available — skipping band power computation.\")\n",
    "            self.relative_power = {}\n",
    "            self.band_df = pd.DataFrame()\n",
    "            return\n",
    "        \n",
    "        res = {}\n",
    "        df = {}\n",
    "        freq_res = self.freqs[1]-self.freqs[0]\n",
    "        for c in self.psd:\n",
    "            res[c] = {}\n",
    "\n",
    "            for ch, P in self.psd[c].items():\n",
    "                if not isinstance(P, np.ndarray) or P.size == 0:\n",
    "                    print(f\"⚠️ Skipping '{ch}' in {self.marker_dict[c]} — invalid PSD shape\")\n",
    "                    continue\n",
    "            \n",
    "                try:\n",
    "                    total = integrate.simpson(P, dx=freq_res)\n",
    "                    res[c][ch] = {}\n",
    "                    for b, (f0, f1) in self.bands.items():\n",
    "                        idx = (self.freqs >= f0) & (self.freqs <= f1)\n",
    "                        bp = integrate.simpson(P[idx], dx=freq_res)\n",
    "                        res[c][ch][b] = bp / total\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error computing band power for '{ch}' in {self.marker_dict[c]}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                    \n",
    "            \n",
    "        self.relative_power = res\n",
    "        # flatten to DataFrame\n",
    "        records = []\n",
    "        for c in res:\n",
    "            label = self.marker_dict[c]\n",
    "            for ch in res[c]:\n",
    "                row = {'Condition':label,'Channel':ch}\n",
    "                row.update(res[c][ch])\n",
    "                records.append(row)\n",
    "        self.band_df = pd.DataFrame(records)\n",
    "\n",
    "    def plot(self, condition: str, ylim=(0,150)):\n",
    "        # find code for condition\n",
    "        inv = {v:k for k,v in self.marker_dict.items()}\n",
    "        code = inv.get(condition)\n",
    "        plt.figure(dpi=120)\n",
    "        for ch, P in self.psd[code].items():\n",
    "            if P is None:\n",
    "                print(f\"⚠️ No PSD for channel '{ch}' — skipping\")\n",
    "                continue\n",
    "            plt.plot(self.freqs, P, label=ch)\n",
    "\n",
    "        plt.xlim(0, max(self.freqs))\n",
    "        plt.ylim(*ylim)\n",
    "        plt.xlabel(\"Frequency (Hz)\")\n",
    "        plt.ylabel(\"Power spectral density (µV²/Hz)\")\n",
    "        plt.title(f\"{condition} – Welch PSD\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_all_epochs(self, channel: str = \"TP9\", ylim=(-100, 100)):\n",
    "        \"\"\"\n",
    "        Plots all EEG trials per stimulus condition for a single channel.\n",
    "        Each condition gets its own subplot.\n",
    "        \"\"\"\n",
    "        n_cond = len(self.events)\n",
    "        if n_cond == 0:\n",
    "            print(\"⚠️ No conditions available to plot.\")\n",
    "            return\n",
    "    \n",
    "        fig, axes = plt.subplots(n_cond, 1, figsize=(12, 4 * n_cond), dpi=100, squeeze=False)\n",
    "        fig.suptitle(f\"EEG epochs – {channel}\", fontsize=16)\n",
    "    \n",
    "        for i, (code, trials_by_channel) in enumerate(self.events.items()):\n",
    "            trials = trials_by_channel.get(channel, [])\n",
    "            ax = axes[i][0]\n",
    "            for trial in trials:\n",
    "                t = np.linspace(0, self.length, len(trial))\n",
    "                ax.plot(t, trial, alpha=0.5)\n",
    "    \n",
    "            label = self.marker_dict.get(code, f\"Code {code}\")\n",
    "            ax.set_title(f\"{label} – {len(trials)} trials\")\n",
    "            ax.set_xlabel(\"Time (s)\")\n",
    "            ax.set_ylabel(\"Amplitude (μV)\")\n",
    "            ax.set_ylim(*ylim)\n",
    "            ax.grid(True)\n",
    "    \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "\n",
    "    def plot_every_trial(self, channel: str = \"TP9\", ylim=(-100, 100)):\n",
    "        \"\"\"\n",
    "        Creates a separate plot for every individual EEG trial across all stimulus types.\n",
    "        Each figure shows one response for a given channel.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        for code, channel_trials in self.events.items():\n",
    "            trials = channel_trials.get(channel, [])\n",
    "            label = self.marker_dict.get(code, f\"Code {code}\")\n",
    "    \n",
    "            for i, trial in enumerate(trials):\n",
    "                t = np.linspace(0, self.length, len(trial))\n",
    "                plt.figure(figsize=(10, 3), dpi=100)\n",
    "                plt.plot(t, trial, label=f\"{label} – Trial {i+1}\")\n",
    "                plt.title(f\"{label} – Trial {i+1} ({channel})\")\n",
    "                plt.xlabel(\"Time (s)\")\n",
    "                plt.ylabel(\"Amplitude (μV)\")\n",
    "                plt.ylim(*ylim)\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                total += 1\n",
    "    \n",
    "        print(f\"✅ Plotted {total} trials across all conditions for channel '{channel}'\")\n",
    "\n",
    "    def plot_every_trial_all_channels(self, ylim=(-100, 100)):\n",
    "        \"\"\"\n",
    "        Creates separate plots for every EEG trial across all stimulus types and all channels.\n",
    "        Each figure shows one response at one channel.\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        for code, channel_trials in self.events.items():\n",
    "            label = self.marker_dict.get(code, f\"Code {code}\")\n",
    "    \n",
    "            for channel, trials in channel_trials.items():\n",
    "                for i, trial in enumerate(trials):\n",
    "                    t = np.linspace(0, self.length, len(trial))\n",
    "                    plt.figure(figsize=(10, 3), dpi=100)\n",
    "                    plt.plot(t, trial, label=f\"{label} – Trial {i+1} – {channel}\")\n",
    "                    plt.title(f\"{label} – Trial {i+1} ({channel})\")\n",
    "                    plt.xlabel(\"Time (s)\")\n",
    "                    plt.ylabel(\"Amplitude (μV)\")\n",
    "                    plt.ylim(*ylim)\n",
    "                    plt.grid(True)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    total += 1\n",
    "    \n",
    "        print(f\"✅ Plotted {total} trial-channel waveforms across all conditions\")\n",
    "\n",
    "    \n",
    "    #TROUBLESHOOTING\n",
    "    def diagnose_trials(self):\n",
    "        \"\"\"\n",
    "        Prints a summary of trial counts:\n",
    "        - Total stimuli per condition from behavioral data\n",
    "        - Trials injected into EEG windows\n",
    "        - Trials retained after cleaning\n",
    "        \"\"\"\n",
    "        print(\"\\n📋 Trial Diagnostics:\")\n",
    "    \n",
    "        # Step 1 — Behavior CSV\n",
    "        if hasattr(self, 'beh') and 'Stimulus' in self.beh.columns:\n",
    "            beh_counts = self.beh[\"Stimulus\"].value_counts()\n",
    "            print(\"🧪 Behavioral stimulus counts:\")\n",
    "            for stim, count in beh_counts.items():\n",
    "                print(f\"  {stim}: {count}\")\n",
    "        else:\n",
    "            print(\"⚠️ Behavioral data not available or missing 'Stimulus' column\")\n",
    "    \n",
    "        # Step 2 — Injected trials from marker_map\n",
    "        print(\"\\n🔗 EEG-aligned trials per condition:\")\n",
    "        for code in self.events:\n",
    "            stim = self.marker_dict.get(code, f\"Code {code}\")\n",
    "            trial_count = len(next(iter(self.events[code].values()), []))\n",
    "            print(f\"  {stim}: {trial_count} trials\")\n",
    "    \n",
    "        # Step 3 — Cleaned windows (after noise filtering)\n",
    "        print(\"\\n🧹 Clean windows retained per condition:\")\n",
    "        for code in self.windows:\n",
    "            stim = self.marker_dict.get(code, f\"Code {code}\")\n",
    "            ch_counts = {ch: len(ws) for ch, ws in self.windows[code].items()}\n",
    "            avg_clean = np.mean(list(ch_counts.values()))\n",
    "            print(f\"  {stim}: ~{int(avg_clean)} clean trials (avg per channel)\")\n",
    "\n",
    "\n",
    "    def tag_noise_levels(self, thresholds=(50, 150)):\n",
    "        \"\"\"\n",
    "        Labels each EEG trial's noise level: 'low', 'medium', or 'high',\n",
    "        based on peak-to-peak amplitude. No trials are removed.\n",
    "        Results are stored in self.noise_labels[condition][channel] = [labels...]\n",
    "        \"\"\"\n",
    "        self.noise_labels = {}\n",
    "    \n",
    "        for code, channel_trials in self.windows.items():\n",
    "            self.noise_labels[code] = {}\n",
    "            label = self.marker_dict.get(code, f\"Code {code}\")\n",
    "    \n",
    "            for ch, trials in channel_trials.items():\n",
    "                level_tags = []\n",
    "                for trial in trials:\n",
    "                    ptp = np.ptp(trial)  # Peak-to-peak amplitude\n",
    "                    if ptp < thresholds[0]:\n",
    "                        level_tags.append(\"low\")\n",
    "                    elif ptp < thresholds[1]:\n",
    "                        level_tags.append(\"medium\")\n",
    "                    else:\n",
    "                        level_tags.append(\"high\")\n",
    "                self.noise_labels[code][ch] = level_tags\n",
    "    \n",
    "        print(\"✅ Noise levels tagged for all trials. No exclusions applied.\")\n",
    "\n",
    "\n",
    "    def get_trials_by_noise(self, levels=(\"low\", \"medium\"), condition=None, channel=\"TP9\"):\n",
    "        \"\"\"\n",
    "        Retrieves trials matching any of the specified noise levels.\n",
    "        Args:\n",
    "            levels (tuple): One or more noise levels ('low', 'medium', 'high')\n",
    "            condition (str): Optional stimulus label (e.g. 'circle')\n",
    "            channel (str): EEG channel name (e.g. 'AF8')\n",
    "        Returns:\n",
    "            List of EEG trials matching criteria\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"noise_labels\"):\n",
    "            print(\"⚠️ Noise labels not found. Run `tag_noise_levels()` first.\")\n",
    "            return []\n",
    "    \n",
    "        matched_trials = []\n",
    "    \n",
    "        for code, ch_labels in self.noise_labels.items():\n",
    "            stim = self.marker_dict.get(code, f\"Code {code}\")\n",
    "            if condition and stim != condition:\n",
    "                continue\n",
    "            if channel not in ch_labels:\n",
    "                continue\n",
    "    \n",
    "            labels = ch_labels[channel]\n",
    "            trials = self.windows[code][channel]\n",
    "    \n",
    "            for trial, lbl in zip(trials, labels):\n",
    "                if lbl in levels:\n",
    "                    matched_trials.append(trial)\n",
    "    \n",
    "        print(f\"✅ Retrieved {len(matched_trials)} trials with noise levels {levels}\" +\n",
    "              (f\" from '{condition}' @ {channel}\" if condition else f\" @ {channel}\"))\n",
    "        return matched_trials\n",
    "\n",
    "\n",
    "    def plot_trials(self, trials, title=\"EEG Trials\", color=\"slateblue\"):\n",
    "        \"\"\"\n",
    "        Plots a list of EEG trials (1D arrays).\n",
    "        Each trial will be plotted as a separate line.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "    \n",
    "        if not trials:\n",
    "            print(\"⚠️ No trials to plot.\")\n",
    "            return\n",
    "    \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for i, trial in enumerate(trials):\n",
    "            plt.plot(trial, alpha=0.5, label=f\"Trial {i+1}\", color=color)\n",
    "    \n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time (samples)\")\n",
    "        plt.ylabel(\"Amplitude (μV)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def dataframe(self):\n",
    "        return self.band_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2cf01-5cfe-487b-b317-0abba8c357ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load EEG (timestamps are already float Unix seconds)\n",
    "eeg_df = load_eeg(eeg_file)\n",
    "\n",
    "# 2. Read behavioral log raw\n",
    "behav_df_raw = pd.read_csv(behav_file)\n",
    "\n",
    "# ✅ 3. Use timestamps directly — no offset\n",
    "beh_df = behav_df_raw.copy()\n",
    "beh_df[\"marker_ts\"] = beh_df[\"Marker Timestamp\"]  # Already in Unix seconds\n",
    "\n",
    "# 4. Build stimulus label-to-code map\n",
    "stim_labels = beh_df[\"Stimulus\"].unique()\n",
    "marker_map = {label: i + 1 for i, label in enumerate(stim_labels)}\n",
    "\n",
    "# 5. Run pipeline\n",
    "session = Recording(\n",
    "    eeg_df,\n",
    "    beh_df,\n",
    "    marker_map,\n",
    "    length=20,\n",
    "    min_freq=1,\n",
    "    max_freq=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af9150f-fd41-4b38-b23a-8b8dce83a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.diagnose_trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e506873-cefb-46f0-aa0f-58de822289f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098f369-8f2f-43d2-be69-9c55eaaa6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in session.dataframe()[\"Condition\"].unique():\n",
    "    session.plot(condition, ylim=(0, 50))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
